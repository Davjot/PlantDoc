{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNaFAvEqA0tmqWjdTTEWbnC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Davjot/PlantDoc/blob/main/image_plantdoc_dn201.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2y5ErwA631bO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate \\\n",
        "  https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoHaTk896_im",
        "outputId": "15a32d37-1e4e-4585-891f-251becf7be83"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-06 10:58:07--  https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.142.128, 74.125.195.128, 74.125.20.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.142.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 74836368 (71M) [application/octet-stream]\n",
            "Saving to: ‘densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "densenet201_weights 100%[===================>]  71.37M   100MB/s    in 0.7s    \n",
            "\n",
            "2023-04-06 10:58:08 (100 MB/s) - ‘densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [74836368/74836368]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import DenseNet201\n",
        "\n",
        "local_weights_file = '/content/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "pre_trained_model = DenseNet201(\n",
        "    input_shape=(299, 299, 3), include_top=False, weights='imagenet')\n",
        "pre_trained_model.load_weights(local_weights_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXcNbK5xNxel",
        "outputId": "6c7aee37-af40-4bf6-b1a4-73280cb09d55"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "74836368/74836368 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-oawC9-OK3Q",
        "outputId": "73e3a704-99fe-432e-86d2-533c6d30134d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "base_dir = '/content/drive/MyDrive/Plantdoc'\n",
        "train_dir = os.path.join(base_dir)\n",
        "validation_dir = os.path.join(base_dir)"
      ],
      "metadata": {
        "id": "YlW2OthkOhbl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_apple_rust_leaf_dir = os.path.join(train_dir, 'Apple rust leaf')\n",
        "validation_apple_rust_leaf_dir = os.path.join(validation_dir, 'Apple rust leaf')\n",
        "train_blueberry_leaf_dir = os.path.join(train_dir, 'Blueberry leaf')\n",
        "validation_blueberry_leaf_dir = os.path.join(validation_dir, 'Blueberry leaf')\n",
        "#train_apple_rust_leaf_fnames = os.listdir(train_apple_rust_leaf_dir) \n",
        "#training set\n",
        "train_apple_leaf_dir = os.path.join(train_dir, 'Apple leaf')\n",
        "train_apple_scab_leaf_dir = os.path.join(train_dir, 'Apple scab leaf')\n",
        "train_bell_pepper_leaf_dir = os.path.join(train_dir, 'Bell pepper leaf')\n",
        "train_bell_pepper_leaf_spot_dir = os.path.join(train_dir, 'Bell pepper leaf spot')\n",
        "train_cherry_leaf_dir = os.path.join(train_dir, 'Cherry leaf')\n",
        "train_corn_gray_leaf_spot_dir = os.path.join(train_dir, 'Corn Gray leaf spot')\n",
        "\n",
        "#validation set\n",
        "validation_apple_leaf_dir = os.path.join(validation_dir, 'Apple leaf')\n",
        "validation_apple_scab_leaf_dir = os.path.join(validation_dir, 'Apple scab leaf')\n",
        "validation_bell_pepper_leaf_dir = os.path.join(validation_dir, 'Bell pepper leaf')\n",
        "validation_bell_pepper_leaf_spot_dir = os.path.join(validation_dir, 'Bell pepper leaf spot')\n",
        "validation_cherry_leaf_dir = os.path.join(validation_dir, 'Cherry leaf')\n",
        "validation_corn_gray_leaf_spot_dir = os.path.join(validation_dir, 'Corn Gray leaf spot')"
      ],
      "metadata": {
        "id": "nhNO603XOjb3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir, # This is the source directory for training images\n",
        "        target_size=(299, 299),  # All images will be resized to 150x150\n",
        "        batch_size=32,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='categorical')\n",
        "\n",
        "# Flow validation images in batches of 20 using val_datagen generator\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(299, 299),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Mvd5SXpOlp4",
        "outputId": "e507be74-b692-4951-9a62-c357e42489de"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 80 images belonging to 8 classes.\n",
            "Found 80 images belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import DenseNet201\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D"
      ],
      "metadata": {
        "id": "E76AhXdiOpF1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the base pre-trained model\n",
        "base_model = DenseNet201(weights='imagenet', include_top=False, input_shape = (299, 299, 3))\n",
        "\n",
        "# add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "# and a logistic layer -- let's say we have 200 classes\n",
        "predictions = Dense(8, activation='softmax')(x)"
      ],
      "metadata": {
        "id": "fUfw254AOpjk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# first: train only the top layers (which were randomly initialized)\n",
        "# i.e. freeze all convolutional InceptionV3 layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "nyawz73iOrgx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=['acc'])"
      ],
      "metadata": {
        "id": "4yQNCxDsOtVw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "my_callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience=2),\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath='/content/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5', save_weights_only = True),\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='/content/drive/MyDrive/logdir_plantdoc_dn201'),\n",
        "]"
      ],
      "metadata": {
        "id": "5eYpehbJOzp4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      epochs=5,\n",
        "      validation_data=validation_generator,\n",
        "      verbose=2,\n",
        "      callbacks = [my_callbacks])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQL7vEvFO15O",
        "outputId": "26b3ed3d-d932-4aa8-c084-9c0fbdb2e1fb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "3/3 - 149s - loss: 2.3134 - acc: 0.1500 - val_loss: 1.7329 - val_acc: 0.3750 - 149s/epoch - 50s/step\n",
            "Epoch 2/5\n",
            "3/3 - 82s - loss: 1.7345 - acc: 0.3500 - val_loss: 1.3446 - val_acc: 0.6750 - 82s/epoch - 27s/step\n",
            "Epoch 3/5\n",
            "3/3 - 81s - loss: 1.3758 - acc: 0.5000 - val_loss: 0.9671 - val_acc: 0.8125 - 81s/epoch - 27s/step\n",
            "Epoch 4/5\n",
            "3/3 - 81s - loss: 1.0526 - acc: 0.7000 - val_loss: 0.7671 - val_acc: 0.7750 - 81s/epoch - 27s/step\n",
            "Epoch 5/5\n",
            "3/3 - 76s - loss: 0.8440 - acc: 0.6875 - val_loss: 0.5396 - val_acc: 0.9250 - 76s/epoch - 25s/step\n"
          ]
        }
      ]
    }
  ]
}