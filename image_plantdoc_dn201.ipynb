{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP26xRAxM7sD0PGw+WpymWs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Davjot/PlantDoc/blob/main/image_plantdoc_dn201.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2y5ErwA631bO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate \\\n",
        "  https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoHaTk896_im",
        "outputId": "7449a640-b6ec-4cfd-e617-830f3f73ef6a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-06 14:14:30--  https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.142.128, 74.125.195.128, 142.250.99.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.142.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 74836368 (71M) [application/octet-stream]\n",
            "Saving to: ‘densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "densenet201_weights 100%[===================>]  71.37M   116MB/s    in 0.6s    \n",
            "\n",
            "2023-04-06 14:14:30 (116 MB/s) - ‘densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [74836368/74836368]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import DenseNet201\n",
        "\n",
        "local_weights_file = '/content/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "pre_trained_model = DenseNet201(\n",
        "    input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
        "pre_trained_model.load_weights(local_weights_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXcNbK5xNxel",
        "outputId": "531aa40e-4e29-414e-b500-99a2494948da"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "74836368/74836368 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-oawC9-OK3Q",
        "outputId": "e36d09a6-28ba-4a2b-8704-cfeaad35e219"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "base_dir = '/content/drive/MyDrive/Plantdoc'\n",
        "train_dir = os.path.join(base_dir)\n",
        "validation_dir = os.path.join(base_dir)"
      ],
      "metadata": {
        "id": "YlW2OthkOhbl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_apple_rust_leaf_dir = os.path.join(train_dir, 'Apple rust leaf')\n",
        "validation_apple_rust_leaf_dir = os.path.join(validation_dir, 'Apple rust leaf')\n",
        "train_blueberry_leaf_dir = os.path.join(train_dir, 'Blueberry leaf')\n",
        "validation_blueberry_leaf_dir = os.path.join(validation_dir, 'Blueberry leaf')\n",
        "#train_apple_rust_leaf_fnames = os.listdir(train_apple_rust_leaf_dir) \n",
        "#training set\n",
        "train_apple_leaf_dir = os.path.join(train_dir, 'Apple leaf')\n",
        "train_apple_scab_leaf_dir = os.path.join(train_dir, 'Apple scab leaf')\n",
        "train_bell_pepper_leaf_dir = os.path.join(train_dir, 'Bell pepper leaf')\n",
        "train_bell_pepper_leaf_spot_dir = os.path.join(train_dir, 'Bell pepper leaf spot')\n",
        "train_cherry_leaf_dir = os.path.join(train_dir, 'Cherry leaf')\n",
        "train_corn_gray_leaf_spot_dir = os.path.join(train_dir, 'Corn Gray leaf spot')\n",
        "\n",
        "#validation set\n",
        "validation_apple_leaf_dir = os.path.join(validation_dir, 'Apple leaf')\n",
        "validation_apple_scab_leaf_dir = os.path.join(validation_dir, 'Apple scab leaf')\n",
        "validation_bell_pepper_leaf_dir = os.path.join(validation_dir, 'Bell pepper leaf')\n",
        "validation_bell_pepper_leaf_spot_dir = os.path.join(validation_dir, 'Bell pepper leaf spot')\n",
        "validation_cherry_leaf_dir = os.path.join(validation_dir, 'Cherry leaf')\n",
        "validation_corn_gray_leaf_spot_dir = os.path.join(validation_dir, 'Corn Gray leaf spot')"
      ],
      "metadata": {
        "id": "nhNO603XOjb3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir, # This is the source directory for training images\n",
        "        target_size=(224, 224),  # All images will be resized to 150x150\n",
        "        batch_size=8,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='categorical')\n",
        "\n",
        "# Flow validation images in batches of 20 using val_datagen generator\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=8,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Mvd5SXpOlp4",
        "outputId": "62aa3f94-2a78-422f-8e5a-e90d8793c6a7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 80 images belonging to 8 classes.\n",
            "Found 80 images belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import DenseNet201\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D"
      ],
      "metadata": {
        "id": "E76AhXdiOpF1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the base pre-trained model\n",
        "base_model = DenseNet201(weights='imagenet', include_top=False, input_shape = (224, 224, 3))\n",
        "\n",
        "# add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "# and a logistic layer -- let's say we have 200 classes\n",
        "predictions = Dense(8, activation='softmax')(x)"
      ],
      "metadata": {
        "id": "fUfw254AOpjk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# first: train only the top layers (which were randomly initialized)\n",
        "# i.e. freeze all convolutional InceptionV3 layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "nyawz73iOrgx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=['acc'])"
      ],
      "metadata": {
        "id": "4yQNCxDsOtVw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "my_callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience=2),\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath='/content/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5', save_weights_only = True),\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='/content/drive/MyDrive/logdir_plantdoc_dn201'),\n",
        "]"
      ],
      "metadata": {
        "id": "5eYpehbJOzp4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      epochs=5,\n",
        "      validation_data=validation_generator,\n",
        "      verbose=2,\n",
        "      callbacks = [my_callbacks])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQL7vEvFO15O",
        "outputId": "27af7d6e-d67e-40d3-c073-b22093dee836"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "10/10 - 99s - loss: 2.2262 - acc: 0.2500 - val_loss: 1.4852 - val_acc: 0.5500 - 99s/epoch - 10s/step\n",
            "Epoch 2/5\n",
            "10/10 - 65s - loss: 1.6518 - acc: 0.4125 - val_loss: 1.0891 - val_acc: 0.6375 - 65s/epoch - 6s/step\n",
            "Epoch 3/5\n",
            "10/10 - 64s - loss: 1.1151 - acc: 0.6000 - val_loss: 0.6982 - val_acc: 0.8500 - 64s/epoch - 6s/step\n",
            "Epoch 4/5\n",
            "10/10 - 65s - loss: 0.8314 - acc: 0.7000 - val_loss: 0.6172 - val_acc: 0.8375 - 65s/epoch - 6s/step\n",
            "Epoch 5/5\n",
            "10/10 - 67s - loss: 0.7788 - acc: 0.7375 - val_loss: 0.3993 - val_acc: 0.9000 - 67s/epoch - 7s/step\n"
          ]
        }
      ]
    }
  ]
}