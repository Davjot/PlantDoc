{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Davjot/PlantDoc/blob/main/Image_plantdoc_IRV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "YPwQPBwChY8O"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAgo9ulthcXU",
        "outputId": "b3c5791f-bd10-4073-b030-e6b343c58b11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-05 15:49:44--  https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.2.128, 142.250.141.128, 2607:f8b0:4023:c0d::80, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.2.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 219055592 (209M) [application/octet-stream]\n",
            "Saving to: ‘inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "inception_resnet_v2 100%[===================>] 208.91M   248MB/s    in 0.8s    \n",
            "\n",
            "2023-04-05 15:49:45 (248 MB/s) - ‘inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [219055592/219055592]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "   https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "J30EX9dohf9x"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "\n",
        "local_weights_file = '/content/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "pre_trained_model = InceptionResNetV2(\n",
        "    input_shape=(299, 299, 3), include_top=False, weights='imagenet')\n",
        "pre_trained_model.load_weights(local_weights_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjPTB6i-hip2",
        "outputId": "09424928-eead-4f78-ae96-c1b3cff433f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "_1elJFH-hpyC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "base_dir = '/content/drive/MyDrive/Plantdoc'\n",
        "train_dir = os.path.join(base_dir)\n",
        "validation_dir = os.path.join(base_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "zI_uPpEbhvOF"
      },
      "outputs": [],
      "source": [
        "train_apple_rust_leaf_dir = os.path.join(train_dir, 'Apple rust leaf')\n",
        "validation_apple_rust_leaf_dir = os.path.join(validation_dir, 'Apple rust leaf')\n",
        "train_blueberry_leaf_dir = os.path.join(train_dir, 'Blueberry leaf')\n",
        "validation_blueberry_leaf_dir = os.path.join(validation_dir, 'Blueberry leaf')\n",
        "#train_apple_rust_leaf_fnames = os.listdir(train_apple_rust_leaf_dir) \n",
        "#training set\n",
        "train_apple_leaf_dir = os.path.join(train_dir, 'Apple leaf')\n",
        "train_apple_scab_leaf_dir = os.path.join(train_dir, 'Apple scab leaf')\n",
        "train_bell_pepper_leaf_dir = os.path.join(train_dir, 'Bell pepper leaf')\n",
        "train_bell_pepper_leaf_spot_dir = os.path.join(train_dir, 'Bell pepper leaf spot')\n",
        "train_cherry_leaf_dir = os.path.join(train_dir, 'Cherry leaf')\n",
        "train_corn_gray_leaf_spot_dir = os.path.join(train_dir, 'Corn Gray leaf spot')\n",
        "\n",
        "#validation set\n",
        "validation_apple_leaf_dir = os.path.join(validation_dir, 'Apple leaf')\n",
        "validation_apple_scab_leaf_dir = os.path.join(validation_dir, 'Apple scab leaf')\n",
        "validation_bell_pepper_leaf_dir = os.path.join(validation_dir, 'Bell pepper leaf')\n",
        "validation_bell_pepper_leaf_spot_dir = os.path.join(validation_dir, 'Bell pepper leaf spot')\n",
        "validation_cherry_leaf_dir = os.path.join(validation_dir, 'Cherry leaf')\n",
        "validation_corn_gray_leaf_spot_dir = os.path.join(validation_dir, 'Corn Gray leaf spot')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79PZ3jsQh3Yg",
        "outputId": "dfcc3d71-124f-4289-b587-1f7e488517a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 80 images belonging to 8 classes.\n",
            "Found 80 images belonging to 8 classes.\n"
          ]
        }
      ],
      "source": [
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir, # This is the source directory for training images\n",
        "        target_size=(299, 299),  # All images will be resized to 150x150\n",
        "        batch_size=32,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='categorical')\n",
        "\n",
        "# Flow validation images in batches of 20 using val_datagen generator\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(299, 299),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "8qTK66bNh5Wt"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "MSXu6YdTiD2B"
      },
      "outputs": [],
      "source": [
        "# create the base pre-trained model\n",
        "base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape = (299, 299, 3))\n",
        "\n",
        "# add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "# and a logistic layer -- let's say we have 200 classes\n",
        "predictions = Dense(8, activation='softmax')(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "i8VpwR9miPfm"
      },
      "outputs": [],
      "source": [
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# first: train only the top layers (which were randomly initialized)\n",
        "# i.e. freeze all convolutional InceptionV3 layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "UCOLxpWGi6WX"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "PWXBLHs7mSdC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "my_callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience=2),\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath='/content/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5', save_weights_only = True),\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='/content/drive/MyDrive/logdir_plantdoc_irv2'),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzcRYdh1jGrJ",
        "outputId": "2101e512-0020-46b4-d1ec-7dde207b1c51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "3/3 - 155s - loss: 2.3769 - acc: 0.1375 - val_loss: 1.8135 - val_acc: 0.5000 - 155s/epoch - 52s/step\n",
            "Epoch 2/5\n",
            "3/3 - 129s - loss: 2.0555 - acc: 0.3250 - val_loss: 1.5894 - val_acc: 0.4875 - 129s/epoch - 43s/step\n",
            "Epoch 3/5\n",
            "3/3 - 131s - loss: 1.6654 - acc: 0.4125 - val_loss: 1.4126 - val_acc: 0.5875 - 131s/epoch - 44s/step\n",
            "Epoch 4/5\n",
            "3/3 - 129s - loss: 1.4485 - acc: 0.5000 - val_loss: 1.2657 - val_acc: 0.5500 - 129s/epoch - 43s/step\n",
            "Epoch 5/5\n",
            "3/3 - 91s - loss: 1.1706 - acc: 0.6000 - val_loss: 1.0870 - val_acc: 0.6125 - 91s/epoch - 30s/step\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      epochs=5,\n",
        "      validation_data=validation_generator,\n",
        "      verbose=2,\n",
        "      callbacks = [my_callbacks])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNeBDT3iUsdjdCoUHBAzELe",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}