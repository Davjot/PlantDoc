{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNg8DHJGuvIWCl26UG4tyUG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Davjot/PlantDoc/blob/main/Image_plantdoc_IRV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "metadata": {
        "id": "YPwQPBwChY8O"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate \\\n",
        "   https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAgo9ulthcXU",
        "outputId": "a5281792-95b2-49f4-b2ce-021bc9a41be2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-05 14:28:14--  https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.141.128, 142.251.2.128, 2607:f8b0:4023:c0d::80, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.141.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 219055592 (209M) [application/octet-stream]\n",
            "Saving to: ‘inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5.1’\n",
            "\n",
            "inception_resnet_v2 100%[===================>] 208.91M   233MB/s    in 0.9s    \n",
            "\n",
            "2023-04-05 14:28:15 (233 MB/s) - ‘inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5.1’ saved [219055592/219055592]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "\n",
        "local_weights_file = '/content/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "pre_trained_model = InceptionResNetV2(\n",
        "    input_shape=(299, 299, 3), include_top=False, weights='imagenet')\n",
        "pre_trained_model.load_weights(local_weights_file)"
      ],
      "metadata": {
        "id": "J30EX9dohf9x"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjPTB6i-hip2",
        "outputId": "a16e736a-860e-4096-a85d-543d6049b70d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "base_dir = '/content/drive/MyDrive/Plantdoc'\n",
        "train_dir = os.path.join(base_dir)\n",
        "validation_dir = os.path.join(base_dir)"
      ],
      "metadata": {
        "id": "_1elJFH-hpyC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_apple_rust_leaf_dir = os.path.join(train_dir, 'Apple rust leaf')\n",
        "validation_apple_rust_leaf_dir = os.path.join(validation_dir, 'Apple rust leaf')\n",
        "train_blueberry_leaf_dir = os.path.join(train_dir, 'Blueberry leaf')\n",
        "validation_blueberry_leaf_dir = os.path.join(validation_dir, 'Blueberry leaf')\n",
        "#train_apple_rust_leaf_fnames = os.listdir(train_apple_rust_leaf_dir) \n",
        "#training set\n",
        "train_apple_leaf_dir = os.path.join(train_dir, 'Apple leaf')\n",
        "train_apple_scab_leaf_dir = os.path.join(train_dir, 'Apple scab leaf')\n",
        "train_bell_pepper_leaf_dir = os.path.join(train_dir, 'Bell pepper leaf')\n",
        "train_bell_pepper_leaf_spot_dir = os.path.join(train_dir, 'Bell pepper leaf spot')\n",
        "train_cherry_leaf_dir = os.path.join(train_dir, 'Cherry leaf')\n",
        "train_corn_gray_leaf_spot_dir = os.path.join(train_dir, 'Corn Gray leaf spot')\n",
        "\n",
        "#validation set\n",
        "validation_apple_leaf_dir = os.path.join(validation_dir, 'Apple leaf')\n",
        "validation_apple_scab_leaf_dir = os.path.join(validation_dir, 'Apple scab leaf')\n",
        "validation_bell_pepper_leaf_dir = os.path.join(validation_dir, 'Bell pepper leaf')\n",
        "validation_bell_pepper_leaf_spot_dir = os.path.join(validation_dir, 'Bell pepper leaf spot')\n",
        "validation_cherry_leaf_dir = os.path.join(validation_dir, 'Cherry leaf')\n",
        "validation_corn_gray_leaf_spot_dir = os.path.join(validation_dir, 'Corn Gray leaf spot')"
      ],
      "metadata": {
        "id": "zI_uPpEbhvOF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir, # This is the source directory for training images\n",
        "        target_size=(299, 299),  # All images will be resized to 150x150\n",
        "        batch_size=32,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='categorical')\n",
        "\n",
        "# Flow validation images in batches of 20 using val_datagen generator\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(299, 299),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79PZ3jsQh3Yg",
        "outputId": "bf7e8be8-7a5e-4bf4-d48e-fefa6fff90a4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 80 images belonging to 8 classes.\n",
            "Found 80 images belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D"
      ],
      "metadata": {
        "id": "8qTK66bNh5Wt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the base pre-trained model\n",
        "base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape = (299, 299, 3))\n",
        "\n",
        "# add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "# and a logistic layer -- let's say we have 200 classes\n",
        "predictions = Dense(8, activation='softmax')(x)"
      ],
      "metadata": {
        "id": "MSXu6YdTiD2B"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# first: train only the top layers (which were randomly initialized)\n",
        "# i.e. freeze all convolutional InceptionV3 layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "i8VpwR9miPfm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=['acc'])"
      ],
      "metadata": {
        "id": "UCOLxpWGi6WX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "my_callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience=2),\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath='/content/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5', save_weights_only = True),\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='/content/drive/MyDrive/logdir_plantdoc'),\n",
        "]"
      ],
      "metadata": {
        "id": "PWXBLHs7mSdC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      epochs=5,\n",
        "      validation_data=validation_generator,\n",
        "      verbose=2,\n",
        "      callbacks = [my_callbacks])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzcRYdh1jGrJ",
        "outputId": "12b5b0f5-cfa3-4b1b-883d-5f9cb97de4f0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "3/3 - 120s - loss: 2.2983 - acc: 0.1375 - val_loss: 1.6251 - val_acc: 0.5125 - 120s/epoch - 40s/step\n",
            "Epoch 2/5\n",
            "3/3 - 91s - loss: 1.7754 - acc: 0.3250 - val_loss: 1.4118 - val_acc: 0.5875 - 91s/epoch - 30s/step\n",
            "Epoch 3/5\n",
            "3/3 - 95s - loss: 1.6731 - acc: 0.3500 - val_loss: 1.3440 - val_acc: 0.6000 - 95s/epoch - 32s/step\n",
            "Epoch 4/5\n",
            "3/3 - 130s - loss: 1.2882 - acc: 0.6000 - val_loss: 1.1401 - val_acc: 0.6000 - 130s/epoch - 43s/step\n",
            "Epoch 5/5\n",
            "3/3 - 93s - loss: 1.1892 - acc: 0.6000 - val_loss: 0.9792 - val_acc: 0.6000 - 93s/epoch - 31s/step\n"
          ]
        }
      ]
    }
  ]
}